{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cb58e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"merged.csv\", low_memory=False)\n",
    "important_features = [\n",
    "    \"Bwd Packet Length Std\", \"Flow Bytes/s\", \"Total Length of Fwd Packets\", \"Fwd Packet Length Std\",\n",
    "    \"Flow IAT Std\", \"Flow IAT Min\", \"Fwd IAT Total\", \"Flow Duration\", \"Bwd Packet Length Max\",\n",
    "    \"Flow IAT Max\", \"Flow IAT Mean\", \"Total Length of Bwd Packets\", \"Fwd Packet Length Min\",\n",
    "    \"Bwd Packet Length Mean\", \"Flow Packets/s\", \"Fwd Packet Length Mean\", \"Total Backward Packets\",\n",
    "    \"Fwd Packet Length Max\", \"Total Fwd Packets\", \"Bwd Packet Length Min\", \"Label\"\n",
    "]\n",
    "\n",
    "df_filtered = df[important_features]\n",
    "df_filtered.to_csv(\"mergedTop20.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32b0d9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training kernel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Kernel Rows: 100%|██████████| 800/800 [1:01:49<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test kernel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Kernel Rows: 100%|██████████| 200/200 [11:53<00:00,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.36      0.52       400\n",
      "           1       0.60      0.97      0.75       400\n",
      "\n",
      "    accuracy                           0.67       800\n",
      "   macro avg       0.77      0.67      0.64       800\n",
      "weighted avg       0.77      0.67      0.64       800\n",
      "\n",
      "\n",
      "Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62       100\n",
      "           1       0.65      1.00      0.78       100\n",
      "\n",
      "    accuracy                           0.72       200\n",
      "   macro avg       0.82      0.72      0.70       200\n",
      "weighted avg       0.82      0.72      0.70       200\n",
      "\n",
      "Time taken: 5307.85 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pennylane as qml\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"mergedTop20.csv\", low_memory=False)\n",
    "cols = [\n",
    "    \"Bwd Packet Length Std\", \"Flow Bytes/s\", \"Total Length of Fwd Packets\", \"Fwd Packet Length Std\",\n",
    "    \"Flow IAT Std\", \"Flow IAT Min\", \"Fwd IAT Total\", \"Flow Duration\", \"Bwd Packet Length Max\",\n",
    "    \"Flow IAT Max\", \"Flow IAT Mean\", \"Total Length of Bwd Packets\", \"Fwd Packet Length Min\",\n",
    "    \"Bwd Packet Length Mean\", \"Flow Packets/s\", \"Fwd Packet Length Mean\", \"Total Backward Packets\",\n",
    "    \"Fwd Packet Length Max\", \"Total Fwd Packets\", \"Bwd Packet Length Min\", \"Label\"\n",
    "]\n",
    "df = df[cols].fillna(0)\n",
    "df[\"Label\"] = df[\"Label\"].apply(lambda x: 1 if x == \"BENIGN\" else 0)\n",
    "\n",
    "# Feature Selection\n",
    "X = df.drop(\"Label\", axis=1)\n",
    "y = df[\"Label\"]\n",
    "top_indices = np.argsort(RandomForestClassifier().fit(X, y).feature_importances_)[::-1][:5]\n",
    "X_top = X.iloc[:, top_indices]\n",
    "\n",
    "# Balancing\n",
    "benign = X_top[y == 1].sample(n=500, random_state=42)\n",
    "attack = X_top[y == 0].sample(n=500, random_state=42)\n",
    "X_bal = pd.concat([benign, attack]).reset_index(drop=True)\n",
    "y_bal = pd.Series([1]*500 + [0]*500)\n",
    "\n",
    "# Scaling & PCA\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_bal)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_bal, test_size=0.2, stratify=y_bal, random_state=42)\n",
    "\n",
    "# Quantum kernel definition\n",
    "n_qubits = X_train.shape[1]\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "def feature_map(x):\n",
    "    for i in range(n_qubits):\n",
    "        qml.Hadamard(wires=i)\n",
    "        qml.RZ(x[i], wires=i)\n",
    "    for i in range(n_qubits - 1):\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "        qml.RZ((x[i] + x[i + 1]) / 2, wires=i + 1)\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def kernel_circuit(x1, x2):\n",
    "    feature_map(x1)\n",
    "    qml.adjoint(feature_map)(x2)\n",
    "    return qml.probs(wires=range(n_qubits))\n",
    "\n",
    "def fidelity(x1, x2):\n",
    "    return kernel_circuit(x1, x2)[0]\n",
    "\n",
    "def create_kernel_matrix(X1, X2):\n",
    "    kernel = np.zeros((len(X1), len(X2)))\n",
    "    for i in tqdm(range(len(X1)), desc=\"Building Kernel Rows\"):\n",
    "        for j in range(len(X2)):\n",
    "            kernel[i, j] = fidelity(X1[i], X2[j])\n",
    "    return kernel\n",
    "\n",
    "# Compute kernel matrices\n",
    "print(\"Generating training kernel...\")\n",
    "kernel_train = create_kernel_matrix(X_train, X_train)\n",
    "\n",
    "print(\"Generating test kernel...\")\n",
    "kernel_test = create_kernel_matrix(X_test, X_train)\n",
    "\n",
    "# Train SVM\n",
    "clf = SVC(kernel=\"precomputed\")\n",
    "clf.fit(kernel_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_train = clf.predict(kernel_train)\n",
    "y_pred_test = clf.predict(kernel_test)\n",
    "\n",
    "print(\"\\nTraining Report:\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "print(\"\\nTest Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Save results\n",
    "os.makedirs(\"Pennylane_Result\", exist_ok=True)\n",
    "joblib.dump(clf, \"Pennylane_Result/pennylane_qsvc.pkl\", compress=3)\n",
    "joblib.dump(scaler, \"Pennylane_Result/pennylane_scaler.pkl\", compress=3)\n",
    "joblib.dump(pca, \"Pennylane_Result/pennylane_pca.pkl\", compress=3)\n",
    "joblib.dump(cols[:-1], \"Pennylane_Result/pennylane_features_used.pkl\", compress=3)\n",
    "\n",
    "print(\"Time taken:\", round(time.time() - start_time, 2), \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
